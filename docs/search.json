[
  {
    "objectID": "slides/01-introduction.html#hello-my-name-is-byron",
    "href": "slides/01-introduction.html#hello-my-name-is-byron",
    "title": "MELODEM data workshop",
    "section": "Hello! My name is Byron",
    "text": "Hello! My name is Byron\n\nI am an R enthusiast.\nI love dogs.\nI study risk  prediction + machine learning"
  },
  {
    "objectID": "slides/01-introduction.html#schedule-for-day-1-morning",
    "href": "slides/01-introduction.html#schedule-for-day-1-morning",
    "title": "MELODEM data workshop",
    "section": "Schedule for day 1: Morning",
    "text": "Schedule for day 1: Morning\nIntroduction, data management (75m)\n\nBreak (15m)\n\nDecision trees and random forests (75m)\n\nBreak (15m)\n\nLunch (1 hour)"
  },
  {
    "objectID": "slides/01-introduction.html#schedule-for-day-1-afternoon",
    "href": "slides/01-introduction.html#schedule-for-day-1-afternoon",
    "title": "MELODEM data workshop",
    "section": "Schedule for day 1: Afternoon",
    "text": "Schedule for day 1: Afternoon\nDevelop and evaluate prediction models (75m)\n\nBreak (15m)\n\nDevelop and evaluate causal models (75m)\n\nBreak (15m)\n\nCollaboration (1 hour)"
  },
  {
    "objectID": "slides/01-introduction.html#schedule-for-day-2-morning",
    "href": "slides/01-introduction.html#schedule-for-day-2-morning",
    "title": "MELODEM data workshop",
    "section": "Schedule for day 2: Morning",
    "text": "Schedule for day 2: Morning\nReview and discuss manuscript aims (30m)\n\nAlign on aims and responsibilities\n\nThree break-out sessions (60m each)\n\nWork independently or in small groups (45m)\nProgress updates (10m)\nBreak (5m)\n\nWrap-up (30m)"
  },
  {
    "objectID": "slides/01-introduction.html#set-up-r-packages",
    "href": "slides/01-introduction.html#set-up-r-packages",
    "title": "MELODEM data workshop",
    "section": "Set-up R packages",
    "text": "Set-up R packages\nMake sure we all have up-to-date versions of these R packages:\n\n# Install required packages for the workshop\npkgs &lt;- \n  c(\"tidyverse\", \"tidymodels\", \"data.table\", \"haven\", \"magrittr\",\n    \"glue\", \"grf\", \"aorsf\", \"glmnet\", \"xgboost\", \"randomForestSRC\",\n    \"party\", \"riskRegression\", \"survival\", \"officer\", \"flextable\", \n    \"table.glue\", \"gtsummary\", \"usethis\", \"cli\")\n\ninstall.packages(pkgs)"
  },
  {
    "objectID": "slides/01-introduction.html#set-up-github",
    "href": "slides/01-introduction.html#set-up-github",
    "title": "MELODEM data workshop",
    "section": "Set-up GitHub",
    "text": "Set-up GitHub\nMake sure we all have GitHub account with personal access token (PAT) stored in Rstudio\n\n\n\nOpen Rstudio\nCopy/paste the code on this slide into an R script\nImportant: adjust destdir\nRun\n\n\n\nlibrary(usethis)\n\ncreate_from_github(\n  \"bcjaeger/melodem-apoe4-het\",\n  destdir = \"path/of/choice\", \n  fork = TRUE\n)"
  },
  {
    "objectID": "slides/01-introduction.html#introducing-targets",
    "href": "slides/01-introduction.html#introducing-targets",
    "title": "MELODEM data workshop",
    "section": "Introducing targets",
    "text": "Introducing targets"
  },
  {
    "objectID": "slides/01-introduction.html#your-turn",
    "href": "slides/01-introduction.html#your-turn",
    "title": "MELODEM data workshop",
    "section": "Your turn",
    "text": "Your turn\n\nOpen _targets.R in the melodem-apoe4-het project.\nRun library(targets) to load the targets package.\nRun tar_glimpse() to inspect the pipeline.\nRun tar_make() to make the pipeline.\n\nWhile you’re working,\n\nPlace red sticky note on the back of your laptop if you want help.\nPlace green sticky note on the back of your laptop when you finish."
  },
  {
    "objectID": "slides/01-introduction.html#working-together-separately.",
    "href": "slides/01-introduction.html#working-together-separately.",
    "title": "MELODEM data workshop",
    "section": "Working together, separately.",
    "text": "Working together, separately.\nWhy do we need all the bells and whistles?\n\nManagement of multiple datasets (targets)\nCoordinating analyses over these datasets (targets)\nLarge amount of code from multiple authors (GitHub)\nCollaborative discussions in public makes better science (GitHub)"
  },
  {
    "objectID": "slides/01-introduction.html#start-with-data-management",
    "href": "slides/01-introduction.html#start-with-data-management",
    "title": "MELODEM data workshop",
    "section": "Start with data management",
    "text": "Start with data management\nIn the _targets.R file:\n\n\n\nfile_sim_1_tar &lt;- tar_target(\n  file_sim_1,\n  command = \"data/sim_1-raw.csv\",\n  format = 'file'\n)\n\ndata_sim_1_tar &lt;- tar_target(\n  data_sim_1,\n  data_prepare(file_sim_1, \n               age_range = c(55, 80))\n)\n\n\n\n\n\nThis will be done with your data, too!"
  },
  {
    "objectID": "slides/01-introduction.html#your-turn-1",
    "href": "slides/01-introduction.html#your-turn-1",
    "title": "MELODEM data workshop",
    "section": "Your turn",
    "text": "Your turn\nWe are going to add your data to the pipeline, carefully.\n\nThink of a name for your data.\n\nExample name: regards\n\nSave a copy of your data in data/sensitive. The name of your file should be name-raw.csv or name-raw.sas7bdat, where name is your data’s name. E.g., regards-raw.csv"
  },
  {
    "objectID": "slides/01-introduction.html#your-turn-2",
    "href": "slides/01-introduction.html#your-turn-2",
    "title": "MELODEM data workshop",
    "section": "Your turn",
    "text": "Your turn\nWe are going to add your data to the pipeline, carefully.\n\nSwitch from the R console to the terminal.\nVerify you have no uncommitted changes:\n\n\ngit status\n\nShould return “nothing to commit, working tree clean”\n\nCreate a new branch with git:\n\n\ngit branch -b regards"
  },
  {
    "objectID": "slides/01-introduction.html#your-turn-3",
    "href": "slides/01-introduction.html#your-turn-3",
    "title": "MELODEM data workshop",
    "section": "Your turn",
    "text": "Your turn\nWe are going to add your data to the pipeline, carefully.\n\n\n\nModify the code beside in _targets.R, replacing x with the name of your data.\nSave the _targets.R file\nRun tar_make() in the R console.\nrun tar_load(data_x), where x is your data name, and print it\n\n\n\nfile_x_tar &lt;- tar_target(               \n  file_x,\n  command = \"data/sensitive/x-raw.csv\"\n  format = \"file\"\n)\n\ndata_x_tar &lt;- tar_target(\n  data_x,\n  data_prepare(cohort_name = \"x\")\n)\n\n# don't forget to add these targets\n# to the targets list at the bottom!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Methods in longitudinal dementia research workshop",
    "section": "",
    "text": "These are the materials for the MEthods in LOngitudinal DEMentia (MELODEM) workshops offered at Château de Bellinglise, France, July 2024.\nThe workshop focuses on the use of random forests to predict dementia risk and identify heterogeneity in the association between APOE4 and dementia risk. This website hosts the materials for the workshop and the corresponding GitHub repository (todo: add link here) includes additional materials for manuscript development."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Methods in longitudinal dementia research workshop",
    "section": "",
    "text": "These are the materials for the MEthods in LOngitudinal DEMentia (MELODEM) workshops offered at Château de Bellinglise, France, July 2024.\nThe workshop focuses on the use of random forests to predict dementia risk and identify heterogeneity in the association between APOE4 and dementia risk. This website hosts the materials for the workshop and the corresponding GitHub repository (todo: add link here) includes additional materials for manuscript development."
  },
  {
    "objectID": "index.html#data-set-requirements",
    "href": "index.html#data-set-requirements",
    "title": "Methods in longitudinal dementia research workshop",
    "section": "Data set requirements",
    "text": "Data set requirements\nData sets must have the following characteristics:\n\na right-censored time-to-dementia outcome.\ndata on APOE4 (any vs none, at minimum).\ndata on age and sex.\nYou personally are able to access it from the venue in France (e.g., Wifi, hard drive)\n\nIf the dataset doesn’t meet all of these criteria, it will not be eligible for the workshop analysis.\nFor efficiency during the workshop, please ensure the names of the required variables are as follows:\n\nTime to dementia should be named ‘time’ and should be numeric time in years from baseline assessment to the time of censoring, death, or dementia, whichever occurred first.\nDementia status should be named ‘status’ and should take values of 0 or 1, with 1 occurring if and only if dementia occurred before censoring and death.\nApoe4 should be named ‘apoe4’ and should have values of ‘carrier’ vs. ‘non_carrier’. Keep this binary for the sake of using it in causal random forests.\nAge should be named ‘age’ and should be numeric with age in years.\nSex should be named ‘sex’ and should include values of ‘male’ or ‘female’. This does not need to be binary if your data have a large sample (i.e., &gt; 250 observations with &gt;10 dementia events) of people who do not identify in either of those two categories\n\nData sets should have as many predictors of dementia risk possible. Predictors would include any variable that\n\nMay be associated with dementia risk\nMay be associated with APOE4 status\nIs not an effect of dementia or cognitive impairment\nMay explain heterogeneity in the association of APOE4 with dementia risk.\n\nData sets need not have an exhaustive set of predictors, but any predictors must be measured before or at the start of follow-up for the right-censored dementia outcome. Because the analysis will be exploratory and focus on the identifying heterogeneity in the association of APOE4 with incident dementia, we encourage everyone to include as many valid predictors from their data as feasible. A few examples include (but are not limited to):\n\neducation,\nrace/ethnicity,\nsmoking history,\nmid-life htn,\nmid-life obesity,\nhtn drugs and statins,\nSES,\ndiabetes,\nrenal disease,\natrial fibrillation,\ncardiovascular disease,\ndepression,\nhead trauma,\ninsomnia,\northostatic hypotension,\nfamily history of cognitive impairment,\nfamily history of Alzheimer’s Disease"
  },
  {
    "objectID": "index.html#preparation",
    "href": "index.html#preparation",
    "title": "Methods in longitudinal dementia research workshop",
    "section": "Preparation",
    "text": "Preparation\nPlease join the workshop with a computer that has the following installed (all available for free):\n\nA recent version of R, available at https://cran.r-project.org/\nA recent version of RStudio Desktop (RStudio Desktop Open Source License, at least v2022.02), available at https://posit.co/download/rstudio-desktop/\nA recent version of git, available at https://git-scm.com/downloads\nThe following R packages, which you can install from the R console:\n\n\n# Install required packages for the workshop\npkgs &lt;- \n  c(\"tidyverse\", \"tidymodels\", \"data.table\", \"haven\", \"magrittr\",\n    \"glue\", \"grf\", \"aorsf\", \"glmnet\", \"xgboost\", \"randomForestSRC\",\n    \"party\", \"riskRegression\", \"survival\", \"officer\", \"flextable\", \n    \"table.glue\", \"gtsummary\", \"usethis\", \"cli\", \"ggforce\",\n    \"rpart\", \"rpart.plot\", \"ranger\", \"withr\")\n\n# A few more packages may be added - this list isn't final yet.\n\ninstall.packages(pkgs)\n\nIf you’re a Windows user and encounter an error message during installation noting a missing Rtools installation, install Rtools using the installer linked here.\n\nGitHub\nA major aim of the workshop will be to establish a baseline of collaboration for developing and publishing a manuscript. We will use GitHub to facilitate this.\n\nIf you do not have a GitHub account, please create one here: https://github.com/\nIf you have a GitHub account, make sure you have a personal access token for HTTPS stored in your local Rstudio. Instructions to do this are provided here: https://happygitwithr.com/https-pat\n\n\n\ntargets\nIn addition to using GitHub, we will also use targets to coordinate our workflow. There will be a brief tutorial for targets during the workshop, but getting familiar with this R package before the workshop is highly encouraged. A full textbook on targets is available: https://books.ropensci.org/targets/.\nReading the following sections prior to the workshop will be very helpful:\n\nIntroduction: https://books.ropensci.org/targets/#intro\nA walk through: https://books.ropensci.org/targets/walkthrough.html\nFunction-based workflow: https://books.ropensci.org/targets/functions.html"
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "Methods in longitudinal dementia research workshop",
    "section": "Slides",
    "text": "Slides\nThese slides are designed to use with live teaching and are published for workshop participants’ convenience. They are not meant as standalone learning materials.\n\nDay 1: Oblique and causal random forests\n\nIntroduction\nDecision trees and random forests\n\n\n\nDay 2: Collaborative analysis and manuscript planning"
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Methods in longitudinal dementia research workshop",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nThis website, including the slides, is made with Quarto and is based on the fantastic workshops developed by the tidymodels team. Please submit an issue (todo: add link to github repo) on the GitHub repo for this workshop if you find something that could be fixed or improved."
  },
  {
    "objectID": "index.html#reuse-and-licensing",
    "href": "index.html#reuse-and-licensing",
    "title": "Methods in longitudinal dementia research workshop",
    "section": "Reuse and licensing",
    "text": "Reuse and licensing\n\nUnless otherwise noted (i.e. not an original creation and reused from another source), these educational materials are licensed under Creative Commons Attribution CC BY-SA 4.0."
  },
  {
    "objectID": "slides/01-introduction.html#your-turn-4",
    "href": "slides/01-introduction.html#your-turn-4",
    "title": "MELODEM data workshop",
    "section": "Your turn",
    "text": "Your turn\nWe are going to add your data to the pipeline, carefully.\n\ndata_sim_1\n\n\n\n------------------------------------- sim_1 ------------------------------------- \n# A tibble: 974 × 8\n   time status apoe4    sex      age biomarker_1 biomarker_2 biomarker_3\n  &lt;dbl&gt;  &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1  3.75      0 normal   female  66.3      0.747      -0.742       -1.71 \n2  5.32      0 elevated female  65.5     -0.562      -0.0513       0.546\n3  5.60      0 normal   male    71.4      0.0133     -0.184        0.826\n4  2.05      0 elevated female  59.5      0.795      -1.32        -1.28 \n5  5.73      0 normal   female  58.5     -0.293       0.191        2.54 \n# ℹ 969 more rows\n\n ----------------------------------  exclusions  ---------------------------------- \n# A tibble: 2 × 2\n  label              n_obs\n  &lt;glue&gt;             &lt;int&gt;\n1 sim_1 participants  1000\n2 Aged 55-80 years     974"
  },
  {
    "objectID": "slides/01-introduction.html#data-management",
    "href": "slides/01-introduction.html#data-management",
    "title": "MELODEM data workshop",
    "section": "Data management",
    "text": "Data management\nWe used data_prepare() to make this object.\nLet’s check out what data_prepare does.\n\ndata_prepare &lt;- function(file_name, ...){\n\n  output &lt;- data_load(file_name) %&gt;%\n    data_clean() %&gt;%\n    data_derive() %&gt;%\n    data_select() %&gt;%\n    data_exclude(...)\n\n  check_names(output$values,\n              c(\"age\", \"sex\", \"apoe4\", \"time\", \"status\"))\n\n  output\n\n}"
  },
  {
    "objectID": "slides/01-introduction.html#data-management-1",
    "href": "slides/01-introduction.html#data-management-1",
    "title": "MELODEM data workshop",
    "section": "Data management",
    "text": "Data management\nWe used data_prepare() to make this object.\nLet’s check out what data_prepare does. First, it loads the data\n\ndata_prepare &lt;- function(file_name, ...){\n\n  output &lt;- data_load(file_name) %&gt;%\n    data_clean() %&gt;%\n    data_derive() %&gt;%\n    data_select() %&gt;%\n    data_exclude(...)\n\n  check_names(output$values,\n              c(\"age\", \"sex\", \"apoe4\", \"time\", \"status\"))\n\n  output\n\n}"
  },
  {
    "objectID": "slides/01-introduction.html#data-management-2",
    "href": "slides/01-introduction.html#data-management-2",
    "title": "MELODEM data workshop",
    "section": "Data management",
    "text": "Data management\nLet’s check out data_load().\n\ndata_load &lt;- function(file_path){\n\n    # ... file management code not shown ...\n  \n  structure(\n    .Data = list(\n      values = data_input,\n      exclusions = tibble(label = glue(\"{cohort_name} participants\"),\n                          n_obs = nrow(data_input))\n    ),\n    class = c(cohort_name, 'melodem_data'),\n    label = cohort_label\n  )\n  \n}"
  },
  {
    "objectID": "slides/01-introduction.html#data-management-3",
    "href": "slides/01-introduction.html#data-management-3",
    "title": "MELODEM data workshop",
    "section": "Data management",
    "text": "Data management\nLet’s check out data_load(). The object returned from this function includes data and a preliminary exclusion table.\n\ndata_load &lt;- function(file_path){\n\n    # ... file management code not shown ...\n  \n  structure(\n    .Data = list(\n      values = data_input,\n      exclusions = tibble(label = glue(\"{cohort_name} participants\"),\n                          n_obs = nrow(data_input))\n    ),\n    class = c(cohort_name, 'melodem_data'),\n    label = cohort_label\n  )\n  \n}"
  },
  {
    "objectID": "slides/01-introduction.html#sowhy-does-this-matter",
    "href": "slides/01-introduction.html#sowhy-does-this-matter",
    "title": "MELODEM data workshop",
    "section": "So…why does this matter?",
    "text": "So…why does this matter?\nEach dataset is unique, and some may require customized preparation:\n\nDifferent elements need to be cleaned.\nDifferent variables need to be derived.\nDifferent variables may be selected.\nDifferent exclusions may be applied.\n\ndata_load makes its output have a customized class based on the name of the dataset so that you, the owner of the data, are in control of these steps that may be uniquely defined for your data."
  },
  {
    "objectID": "slides/01-introduction.html#whole-game",
    "href": "slides/01-introduction.html#whole-game",
    "title": "MELODEM data workshop",
    "section": "Whole game",
    "text": "Whole game\nFirst, you pull code down from the GitHub repo."
  },
  {
    "objectID": "slides/01-introduction.html#whole-game-1",
    "href": "slides/01-introduction.html#whole-game-1",
    "title": "MELODEM data workshop",
    "section": "Whole game",
    "text": "Whole game\nNext, you commit code and summary results. No data!"
  },
  {
    "objectID": "slides/01-introduction.html#whole-game-2",
    "href": "slides/01-introduction.html#whole-game-2",
    "title": "MELODEM data workshop",
    "section": "Whole game",
    "text": "Whole game\nLast, you push your code and summary results to the GitHub repo."
  },
  {
    "objectID": "slides/01-introduction.html#why-github",
    "href": "slides/01-introduction.html#why-github",
    "title": "MELODEM data workshop",
    "section": "Why GitHub?",
    "text": "Why GitHub?\nSo we can work together, separately!\n\nStore and coordinate code from multiple authors\nPublic facing team science\nFree website for our work (i.e., this workshop)."
  },
  {
    "objectID": "slides/01-introduction.html#pull",
    "href": "slides/01-introduction.html#pull",
    "title": "MELODEM data workshop",
    "section": "Pull!",
    "text": "Pull!\nMake sure you have a GitHub account with personal access token (PAT) stored in Rstudio\n\n\n\nOpen Rstudio\nCopy/paste the code on this slide into an R script\nImportant: adjust destdir\nRun\n\n\n\nlibrary(usethis)\n\ncreate_from_github(\n  \"bcjaeger/melodem-apoe4-het\",\n  destdir = \"path/of/choice\", \n  fork = TRUE\n)"
  },
  {
    "objectID": "slides/01-introduction.html#data-management-4",
    "href": "slides/01-introduction.html#data-management-4",
    "title": "MELODEM data workshop",
    "section": "Data management",
    "text": "Data management\nThe object returned also has customized class based on the dataset. The output also belongs to a broader class called melodem_data\n\ndata_load &lt;- function(file_path){\n\n  # ... file management code not shown ...\n  \n  structure(\n    .Data = list(\n      values = data_input,\n      exclusions = tibble(label = glue(\"{cohort_name} participants\"),\n                          n_obs = nrow(data_input))\n    ),\n    class = c(cohort_name, 'melodem_data'),\n    label = cohort_label\n  )\n  \n}"
  },
  {
    "objectID": "slides/01-introduction.html#why",
    "href": "slides/01-introduction.html#why",
    "title": "MELODEM data workshop",
    "section": "Why?",
    "text": "Why?\nEach dataset is unique, and some may require customized preparation:\n\nDifferent elements need to be cleaned.\nDifferent variables need to be derived.\nDifferent variables may be selected.\nDifferent exclusions may be applied.\n\ndata_load makes its output have a customized class based on the name of the dataset so that you, the owner of the data, are in control of these steps that may be uniquely defined for your data."
  },
  {
    "objectID": "slides/01-introduction.html#how",
    "href": "slides/01-introduction.html#how",
    "title": "MELODEM data workshop",
    "section": "How?",
    "text": "How?\nR’s generic function system. Generic functions (e.g., plot()) dispatch different methods depending on the type of input object.\n\nHere’s a look at the generic function for cleaning an object of class sim_1:\n\ndata_clean.sim_1 &lt;- function(data){\n  dt &lt;- as.data.table(data$values)\n  dt[, age := age * 5 + 65]\n  dt[, sex := fifelse(sex &gt; 0, 1, 0)]\n  dt[, sex := factor(sex, levels = c(0, 1),\n                     labels = c(\"male\", \"female\"))]\n  data$values &lt;- dt\n  data\n}"
  },
  {
    "objectID": "slides/01-introduction.html#how-1",
    "href": "slides/01-introduction.html#how-1",
    "title": "MELODEM data workshop",
    "section": "How?",
    "text": "How?\nR’s generic function system. Generic functions (e.g., plot()) dispatch different methods depending on the type of input object.\n\nHere’s the generic function for cleaning an object of class melodem_data:\n\ndata_clean.melodem_data &lt;- function(data){\n\n  data\n\n}"
  },
  {
    "objectID": "slides/01-introduction.html#your-data",
    "href": "slides/01-introduction.html#your-data",
    "title": "MELODEM data workshop",
    "section": "Your data",
    "text": "Your data\n\nYour data’s first class is the name you picked, e.g., regards, and second class is melodem_data. Verify by running class()\nWhen you run data_clean() with, e.g., the regards data,\n\nR will first look for a function called data_clean.regards\nIf it doesn’t exist, R runs data_clean.melodem_data\n\n\nTLDR: If you don’t write a specific function for data_clean, data_derive, etc. for your data, then these functions will not do anything to your data."
  },
  {
    "objectID": "slides/01-introduction.html#your-turn-5",
    "href": "slides/01-introduction.html#your-turn-5",
    "title": "MELODEM data workshop",
    "section": "Your turn",
    "text": "Your turn\nFor the rest of this session,\n\nImplement specific data_clean, data_derive, data_select, and data_exclude for your data.\nIf you already did these operations before the workshop, move the code you used into the corresponding function.\nIf you finish early, help someone else!\n\nAt a minimum, make sure your data have time/status for dementia, apoe4, age, and sex, so that you will be able to use your data for the rest of the workshop.\n\n\nSlides available at https://bcjaeger.github.io/melodem-apoe4-het/"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#planting-seeds-for-causal-trees",
    "href": "slides/02-trees_and_forests.html#planting-seeds-for-causal-trees",
    "title": "Decision trees and random forests",
    "section": "Planting seeds for causal trees",
    "text": "Planting seeds for causal trees\nSuppose we have outcome \\(Y\\) and treatment \\(W\\in\\{0, 1\\}\\).\n\\[\\text{Define }\\tau = E[Y|W=1] - E[Y|W=0],\\]\nIf \\(\\tau\\) can be estimated conditional on a person’s characteristics, then a decision tree could be grown using \\(\\hat\\tau_1 \\mid x_1, \\ldots, \\hat\\tau_n \\mid x_n\\) as an outcome. That tree could predict who benefits from treatment and explain why.\n\nBut how do we get \\(\\hat\\tau_i \\mid x_i\\)? More on this later…"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forests",
    "href": "slides/02-trees_and_forests.html#random-forests",
    "title": "MELODEM data workshop",
    "section": "Random Forests",
    "text": "Random Forests\nIf we have to make a yes/no decision, who should make it?\n\n\n1 expert who is right 75% of the time\nMajority rule by 5000 independent “weak experts”.\n\nNote: each weak expert is right 51% of the time.\n\nAnswer is weak experts!"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forests-1",
    "href": "slides/02-trees_and_forests.html#random-forests-1",
    "title": "Decision trees and random forests",
    "section": "Random Forests",
    "text": "Random Forests\nIf we have to make a yes/no decision, who should make it?\n\n\n1 expert who is right 75% of the time\nMajority rule by 5000 independent “weak experts”.\n\nNote: each weak expert is right 51% of the time.\n\nAnswer is weak experts!"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forests-2",
    "href": "slides/02-trees_and_forests.html#random-forests-2",
    "title": "Decision trees and random forests",
    "section": "Random Forests",
    "text": "Random Forests\nIf we have to make a yes/no decision, who should make it?\n\n1 expert who is right 75% of the time\nMajority rule by 5000 independent “weak experts”.\n\nNote: each weak expert is right 51% of the time.\n\nAnswer is weak experts!\n\nWhy? Weak expert majority is right ~92% of the time\n\n# probability that &gt;2500 weak experts are right\n# = 1 - probability that &lt;=2500 are right\n1 - pbinom(q = 2500, size = 5000, prob = 0.51)\n\n[1] 0.9192858"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forests-3",
    "href": "slides/02-trees_and_forests.html#random-forests-3",
    "title": "Decision trees and random forests",
    "section": "Random Forests",
    "text": "Random Forests\nThe weak expert approach for decision trees:\n\nGrow each tree with a random subset of the training data.\n\n“In-bag” means in the random subset\n“Out-of-bag” means not in the subset\n\nEvaluate a random subset of predictors when splitting data.\n\nThese random elements help make the trees more independent while keeping their prediction accuracy better than random guesses."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#axis-based-and-oblique-trees",
    "href": "slides/02-trees_and_forests.html#axis-based-and-oblique-trees",
    "title": "Decision trees and random forests",
    "section": "Axis based and oblique trees",
    "text": "Axis based and oblique trees\nAxis based trees use a single predictor to split data.\nOblique trees use a weighted combination of two or more predictors"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#axis-based-vs-oblique",
    "href": "slides/02-trees_and_forests.html#axis-based-vs-oblique",
    "title": "Decision trees and random forests",
    "section": "Axis based vs oblique",
    "text": "Axis based vs oblique\n\nLeo Breiman found oblique random forests compared more favorably to boosting than axis based ones.1\nOther benchmarks have found the same result.2 Oblique random forests have high prediction accuracy.3\n\nBreiman L. Random forests. Machine learning. 2001 Oct;45:5-32.Katuwal R, Suganthan PN, Zhang L. Heterogeneous oblique random forest. Pattern Recognition. 2020 Mar 1;99:107078.Menze BH, Kelm BM, Splitthoff DN, Koethe U, Hamprecht FA. On oblique random forests. Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2011, Athens, Greece, September 5-9, 2011, Proceedings, Part II 22 2011 (pp. 453-469). Springer Berlin Heidelberg."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#aorsf-benchmark",
    "href": "slides/02-trees_and_forests.html#aorsf-benchmark",
    "title": "Decision trees and random forests",
    "section": "aorsf Benchmark1",
    "text": "aorsf Benchmark1\nGoal: Test if a fast version of the oblique random survival forest (aorsf) is as good as the original (obliqueRSF).\n\nEvaluated both in 35 risk prediction tasks (21 datasets)\nMeasured computation time, C-statistic and index of prediction accuracy (IPA).\nUsed Bayesian linear mixed models to test for differences in expected C-statistic and IPA.\n\nJaeger BC, Welden S, Lenoir K, Speiser JL, Segar MW, Pandey A, Pajewski NM. Accelerated and interpretable oblique random survival forests. Journal of Computational and Graphical Statistics. 2023 Aug 3:1-6."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nDecision trees are grown by recursively splitting a set of training data."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-1",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-1",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nFor classification, “Gini impurity” measures split quality:\n\\[G = 1 - \\sum_{i = 1}^{K} P(i)^2\\]\n\\(K\\) is no. of classes, \\(P(i)\\) is the probability of class \\(i\\)."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-2",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-2",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nConsider splitting at flipper length of 206.5: Right node:\n\ngini_right &lt;- penguins %&gt;% \n filter(flipper_length_mm&gt;=206.5) %&gt;% \n count(species) %&gt;% \n mutate(p = n / sum(n)) %&gt;% \n summarize(gini = 1 - sum(p^2)) %&gt;% \n pull(gini)\n\ngini_right\n\n[1] 0.107008"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-3",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-3",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nConsider splitting at flipper length of 206.5: Left node:\n\ngini_left &lt;- penguins %&gt;% \n filter(flipper_length_mm&lt;206.5) %&gt;% \n count(species) %&gt;% \n mutate(p = n / sum(n)) %&gt;% \n summarize(gini = 1 - sum(p^2)) %&gt;% \n pull(gini)\n\ngini_left\n\n[1] 0.4289479"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-4",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-4",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nConsider splitting at flipper length of 206.5: Impurity:\n\nsplit_var &lt;- penguins %&gt;% \n  pull(flipper_length_mm)\n\nn_tot &lt;- length(split_var)\nn_right &lt;- sum(split_var &gt;= 206.5)\nn_left &lt;- sum(split_var &lt; 206.5)\n\ngini_right * (n_right / n_tot) + \n  gini_left * (n_left / n_tot)\n\n[1] 0.3080996"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-5",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-5",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nNow we have two potential datasets, or nodes in the tree, that we can split.\nDo we keep going or stop?"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-6",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-6",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nWe may stop tree growth if the node has:\n\nObs &lt; min_obs\nCases &lt; min_cases\nImpurity &lt; min_impurity\nDepth = max_depth"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-7",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-7",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nSuppose\n\nmin_obs = 10\nmin_cases = 2\nmin_impurity = 0.2\nmax_depth = 3\n\nWhich node(s) can we split?"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-8",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-8",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\n\nThe left node can be split.\nThe right node cannot, since impurity on the right is &lt; min_impurity"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#partitions-as-a-tree",
    "href": "slides/02-trees_and_forests.html#partitions-as-a-tree",
    "title": "MELODEM data workshop",
    "section": "Partitions as a tree",
    "text": "Partitions as a tree\nThe same partitions, visualized as a binary tree."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-9",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-9",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\n\nThe left node can be split.\nAfter splitting the left node, all nodes have impurity &lt; min_impurity.\nIf no more nodes to grow, convert partitioned sets into leaf nodes"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#your-turn",
    "href": "slides/02-trees_and_forests.html#your-turn",
    "title": "Decision trees and random forests",
    "section": "Your turn",
    "text": "Your turn\nWas this the best possible split? Let’s find out.\n\nOpen classwork/02-trees_and_forests.qmd\nCalculate the total impurity of splitting along bill length of 45 mm.\nReminder: Red sticky note if you’d like help, green sticky note when you are finished.\nHint: the answer is 0.492340868530637"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-10",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-10",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\n\nWhat is a leaf node?\n\nA leaf node is a terminal node in the tree.\nPredictions for new data are stored in leaf nodes.\n\n\n\n\nmutate(\n  penguins,\n  node = case_when(\n    flipper_length_mm &gt;= 206.5 ~ 'leaf_1',\n    bill_length_mm &gt;= 43.35 ~ 'leaf_2',\n    TRUE ~ 'leaf_3'\n  )\n) %&gt;% \n  group_by(node) %&gt;% count(species) %&gt;% \n  mutate(n = n / sum(n)) %&gt;% \n  pivot_wider(values_from = n, names_from = species, \n              values_fill = 0)\n\n# A tibble: 3 × 4\n# Groups:   node [3]\n  node   Adelie Chinstrap Gentoo\n  &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 leaf_1 0.016     0.04   0.944 \n2 leaf_2 0.0635    0.921  0.0159\n3 leaf_3 0.966     0.0345 0"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#your-turn-1",
    "href": "slides/02-trees_and_forests.html#your-turn-1",
    "title": "Decision trees and random forests",
    "section": "Your turn",
    "text": "Your turn\n\nSuppose\n\nmin_obs = 10\nmin_cases = 2\nmin_impurity = 0.2\nmax_depth = 3\n\nWhich node(s) can we split?"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#growing-decision-trees-11",
    "href": "slides/02-trees_and_forests.html#growing-decision-trees-11",
    "title": "Decision trees and random forests",
    "section": "Growing decision trees",
    "text": "Growing decision trees\nThe same partitions, visualized as a binary tree.\n\nAs a reminder, here is our ‘hand-made’ leaf data\n\n\n\n\n\n\n  \n    \n      \n      Adelie\n      Chinstrap\n      Gentoo\n    \n  \n  \n    leaf_1\n0.02\n0.04\n0.94\n    leaf_2\n0.06\n0.92\n0.02\n    leaf_3\n0.97\n0.03\n0.00"
  },
  {
    "objectID": "slides/02-trees_and_forests.html",
    "href": "slides/02-trees_and_forests.html",
    "title": "MELODEM data workshop",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = FALSE, \n                      message = FALSE,\n                      warning = FALSE,\n                      dpi = 300,\n                      cache = TRUE,\n                      fig.height = 6.5,\n                      fig.align = 'center')\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\npenguins &lt;- drop_na(penguins)\n\nwithr::with_dir(\n  new = here::here(),\n  targets::tar_load(penguin_figs)\n)"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#footnotes",
    "href": "slides/02-trees_and_forests.html#footnotes",
    "title": "MELODEM data workshop",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBreiman L. Random forests. Machine learning. 2001 Oct;45:5-32.↩︎\nKatuwal R, Suganthan PN, Zhang L. Heterogeneous oblique random forest. Pattern Recognition. 2020 Mar 1;99:107078.↩︎\nMenze BH, Kelm BM, Splitthoff DN, Koethe U, Hamprecht FA. On oblique random forests. Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2011, Athens, Greece, September 5-9, 2011, Proceedings, Part II 22 2011 (pp. 453-469). Springer Berlin Heidelberg.↩︎\nJaeger BC, Welden S, Lenoir K, Speiser JL, Segar MW, Pandey A, Pajewski NM. Accelerated and interpretable oblique random survival forests. Journal of Computational and Graphical Statistics. 2023 Aug 3:1-6.↩︎"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag",
    "href": "slides/02-trees_and_forests.html#out-of-bag",
    "title": "MELODEM data workshop",
    "section": "Out-of-bag",
    "text": "Out-of-bag\nOut of bag predictions are helpful for estimation and inference"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-1",
    "href": "slides/02-trees_and_forests.html#out-of-bag-1",
    "title": "MELODEM data workshop",
    "section": "Out-of-bag",
    "text": "Out-of-bag"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-2",
    "href": "slides/02-trees_and_forests.html#out-of-bag-2",
    "title": "MELODEM data workshop",
    "section": "Out-of-bag",
    "text": "Out-of-bag"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-3",
    "href": "slides/02-trees_and_forests.html#out-of-bag-3",
    "title": "MELODEM data workshop",
    "section": "Out-of-bag",
    "text": "Out-of-bag"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-4",
    "href": "slides/02-trees_and_forests.html#out-of-bag-4",
    "title": "MELODEM data workshop",
    "section": "Out-of-bag",
    "text": "Out-of-bag"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-predictions",
    "href": "slides/02-trees_and_forests.html#out-of-bag-predictions",
    "title": "Decision trees and random forests",
    "section": "Out-of-bag predictions",
    "text": "Out-of-bag predictions\nFinal out-of-bag predictions:\n\\[\\frac{\\text{out-of-bag predictions}}{\\text{out-of-bag denominator}}\\]\n\nWith conventional bootstrap sampling, each observation has about a 36.8% chance of being out-of-bag for each tree.\nOut-of-bag predictions give an unbiased view of the forest’s prediction on new data\nThis allows for variable importance estimates and (we’ll see this later) valid inference in causal forests."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-predictions-1",
    "href": "slides/02-trees_and_forests.html#out-of-bag-predictions-1",
    "title": "Decision trees and random forests",
    "section": "Out-of-bag predictions",
    "text": "Out-of-bag predictions"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-predictions-2",
    "href": "slides/02-trees_and_forests.html#out-of-bag-predictions-2",
    "title": "Decision trees and random forests",
    "section": "Out-of-bag predictions",
    "text": "Out-of-bag predictions"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-predictions-3",
    "href": "slides/02-trees_and_forests.html#out-of-bag-predictions-3",
    "title": "Decision trees and random forests",
    "section": "Out-of-bag predictions",
    "text": "Out-of-bag predictions"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-predictions-4",
    "href": "slides/02-trees_and_forests.html#out-of-bag-predictions-4",
    "title": "Decision trees and random forests",
    "section": "Out-of-bag predictions",
    "text": "Out-of-bag predictions"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#out-of-bag-predictions-5",
    "href": "slides/02-trees_and_forests.html#out-of-bag-predictions-5",
    "title": "Decision trees and random forests",
    "section": "Out-of-bag predictions",
    "text": "Out-of-bag predictions\nFinal out-of-bag predictions:\n\\[\\frac{\\text{out-of-bag predictions}}{\\text{out-of-bag denominator}}\\]\n\nWith conventional bootstrap sampling, each observation has about a 36.8% chance of being out-of-bag for each tree.\nOut-of-bag predictions give an unbiased view of the forest’s prediction on new data\nThis allows for variable importance estimates and (we’ll see this later) valid inference in causal forests."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#variable-importance",
    "href": "slides/02-trees_and_forests.html#variable-importance",
    "title": "Decision trees and random forests",
    "section": "Variable importance",
    "text": "Variable importance\n\nFirst compute out-of-bag prediction accuracy.\nIn this case, classification accuracy is 96%"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#variable-importance-1",
    "href": "slides/02-trees_and_forests.html#variable-importance-1",
    "title": "Decision trees and random forests",
    "section": "Variable importance",
    "text": "Variable importance\n\nNext, permute the values of a given variable\nSee how one value of flipper length is permuted in the figure?"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#variable-importance-2",
    "href": "slides/02-trees_and_forests.html#variable-importance-2",
    "title": "Decision trees and random forests",
    "section": "Variable importance",
    "text": "Variable importance\n\nNext, permute the values of a given variable\nNow they are all permuted, and out-of-bag classification accuracy is now 61%"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#variable-importance-3",
    "href": "slides/02-trees_and_forests.html#variable-importance-3",
    "title": "Decision trees and random forests",
    "section": "Variable importance",
    "text": "Variable importance\n\nRinse and repeat for all variables.\nFor bill length, out-of-bag classification accuracy is reduced to 63%"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#variable-importance-4",
    "href": "slides/02-trees_and_forests.html#variable-importance-4",
    "title": "Decision trees and random forests",
    "section": "Variable importance",
    "text": "Variable importance\nOnce all variables have been through this process:\n\\[\\text{Variable importance} = \\text{initial accuracy} - \\text{permuted accuracy}\\]\n\nFlipper length: 0.96 - 0.61 = 0.35\nBill length: 0.96 - 0.63 = 0.33\n\n\\(\\Rightarrow\\) flippers more important than bills for species prediction."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forests-4",
    "href": "slides/02-trees_and_forests.html#random-forests-4",
    "title": "Decision trees and random forests",
    "section": "Random Forests",
    "text": "Random Forests\nTo get a prediction from the random forest,\n\npredict the outcome with each tree\ntake the majority vote\n\nIn situations where trees predictions are continuous and you can’t take a majority vote, e.g., predicted 10-year risk for dementia, just take the mean of the tree’s predictions."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forests-5",
    "href": "slides/02-trees_and_forests.html#random-forests-5",
    "title": "Decision trees and random forests",
    "section": "Random Forests",
    "text": "Random Forests\n\nAggregating randomized trees gives the classic random forest"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forests-6",
    "href": "slides/02-trees_and_forests.html#random-forests-6",
    "title": "Decision trees and random forests",
    "section": "Random Forests",
    "text": "Random Forests\n\nAggregating randomized trees gives the classic random forest"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forests-7",
    "href": "slides/02-trees_and_forests.html#random-forests-7",
    "title": "Decision trees and random forests",
    "section": "Random Forests",
    "text": "Random Forests\n\nAggregating randomized trees gives the classic random forest"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#overview",
    "href": "slides/02-trees_and_forests.html#overview",
    "title": "Decision trees and random forests",
    "section": "Overview",
    "text": "Overview\n\nDecision trees\n\nGrowing trees\nLeaf nodes\n\nRandom Forests\n\nOut-of-bag predictions\nVariable importance\n\nAxis-based and oblique\n\nBenchmarks\nSoftware"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#gini-impurity",
    "href": "slides/02-trees_and_forests.html#gini-impurity",
    "title": "Decision trees and random forests",
    "section": "Gini impurity",
    "text": "Gini impurity\n\nFor classification, “Gini impurity” measures split quality:\n\\[G = 1 - \\sum_{i = 1}^{K} P(i)^2\\]\n\\(K\\) is no. of classes, \\(P(i)\\) is the probability of class \\(i\\)."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#first-split-right-node",
    "href": "slides/02-trees_and_forests.html#first-split-right-node",
    "title": "Decision trees and random forests",
    "section": "First split: right node",
    "text": "First split: right node\n\nConsider splitting at flipper length of 206.5: Right node:\n\ngini_right &lt;- penguins %&gt;% \n filter(flipper_length_mm&gt;=206.5) %&gt;% \n count(species) %&gt;% \n mutate(p = n / sum(n)) %&gt;% \n summarize(gini = 1 - sum(p^2)) %&gt;% \n pull(gini)\n\ngini_right\n\n[1] 0.107008"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#first-split-left-node",
    "href": "slides/02-trees_and_forests.html#first-split-left-node",
    "title": "Decision trees and random forests",
    "section": "First split: left node",
    "text": "First split: left node\n\nConsider splitting at flipper length of 206.5: Left node:\n\ngini_left &lt;- penguins %&gt;% \n filter(flipper_length_mm&lt;206.5) %&gt;% \n count(species) %&gt;% \n mutate(p = n / sum(n)) %&gt;% \n summarize(gini = 1 - sum(p^2)) %&gt;% \n pull(gini)\n\ngini_left\n\n[1] 0.4289479"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#first-split-total-impurity",
    "href": "slides/02-trees_and_forests.html#first-split-total-impurity",
    "title": "Decision trees and random forests",
    "section": "First split: total impurity",
    "text": "First split: total impurity\n\nConsider splitting at flipper length of 206.5: Impurity:\n\nsplit_var &lt;- penguins %&gt;% \n  pull(flipper_length_mm)\n\nn_tot &lt;- length(split_var)\nn_right &lt;- sum(split_var &gt;= 206.5)\nn_left &lt;- sum(split_var &lt; 206.5)\n\ngini_right * (n_right / n_tot) + \n  gini_left * (n_left / n_tot)\n\n[1] 0.3080996"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#keep-growing",
    "href": "slides/02-trees_and_forests.html#keep-growing",
    "title": "Decision trees and random forests",
    "section": "Keep growing?",
    "text": "Keep growing?\n\nNow we have two potential datasets, or nodes in the tree, that we can split.\nDo we keep going or stop?"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#stopping-conditions",
    "href": "slides/02-trees_and_forests.html#stopping-conditions",
    "title": "Decision trees and random forests",
    "section": "Stopping conditions",
    "text": "Stopping conditions\n\nWe may stop tree growth if the node has:\n\nObs &lt; min_obs\nCases &lt; min_cases\nImpurity &lt; min_impurity\nDepth = max_depth"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#split-the-left-node",
    "href": "slides/02-trees_and_forests.html#split-the-left-node",
    "title": "Decision trees and random forests",
    "section": "Split the left node",
    "text": "Split the left node\n\n\nThe left node can be split.\nThe right node cannot, since impurity on the right is &lt; min_impurity"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#finished-growing",
    "href": "slides/02-trees_and_forests.html#finished-growing",
    "title": "Decision trees and random forests",
    "section": "Finished growing",
    "text": "Finished growing\n\n\nThe left node can be split.\nAfter splitting the left node, all nodes have impurity &lt; min_impurity.\nIf no more nodes to grow, convert partitioned sets into leaf nodes"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#leaves",
    "href": "slides/02-trees_and_forests.html#leaves",
    "title": "Decision trees and random forests",
    "section": "Leaves?",
    "text": "Leaves?\n\nWhat is a leaf node?\n\nA leaf node is a terminal node in the tree.\nPredictions for new data are stored in leaf nodes.\n\n\n\n\nmutate(\n  penguins,\n  node = case_when(\n    flipper_length_mm &gt;= 206.5 ~ 'leaf_1',\n    bill_length_mm &gt;= 43.35 ~ 'leaf_2',\n    TRUE ~ 'leaf_3'\n  )\n) %&gt;% \n  group_by(node) %&gt;% count(species) %&gt;% \n  mutate(n = n / sum(n)) %&gt;% \n  pivot_wider(values_from = n, names_from = species, \n              values_fill = 0)\n\n# A tibble: 3 × 4\n# Groups:   node [3]\n  node   Adelie Chinstrap Gentoo\n  &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 leaf_1 0.016     0.04   0.944 \n2 leaf_2 0.0635    0.921  0.0159\n3 leaf_3 0.966     0.0345 0"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#your-turn-2",
    "href": "slides/02-trees_and_forests.html#your-turn-2",
    "title": "Decision trees and random forests",
    "section": "Your turn",
    "text": "Your turn\nFit your own decision tree to the penguins data.\n\nOpen classwork/02-trees_and_forests.qmd\nComplete Exercise 2"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#from-partition-to-flowchart",
    "href": "slides/02-trees_and_forests.html#from-partition-to-flowchart",
    "title": "Decision trees and random forests",
    "section": "From partition to flowchart",
    "text": "From partition to flowchart\nThe same partitions, visualized as a binary tree.\n\nAs a reminder, here is our ‘hand-made’ leaf data\n\n\n\n\n\n\n  \n    \n      \n      Adelie\n      Chinstrap\n      Gentoo\n    \n  \n  \n    leaf_1\n0.02\n0.04\n0.94\n    leaf_2\n0.06\n0.92\n0.02\n    leaf_3\n0.97\n0.03\n0.00"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#expert-of-committee",
    "href": "slides/02-trees_and_forests.html#expert-of-committee",
    "title": "Decision trees and random forests",
    "section": "Expert of committee?",
    "text": "Expert of committee?\nIf we have to make a yes/no decision, who should make it?\n\n\n1 expert who is right 75% of the time\nMajority rule by 5000 independent “weak experts”.\n\nNote: each weak expert is right 51% of the time.\n\nAnswer is weak experts!"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#why-committee",
    "href": "slides/02-trees_and_forests.html#why-committee",
    "title": "Decision trees and random forests",
    "section": "Why committee?",
    "text": "Why committee?\nIf we have to make a yes/no decision, who should make it?\n\n1 expert who is right 75% of the time\nMajority rule by 5000 independent “weak experts”.\n\nNote: each weak expert is right 51% of the time.\n\nAnswer is weak experts!\n\nWhy? Weak expert majority is right ~92% of the time\n\n# probability that &gt;2500 weak experts are right\n# = 1 - probability that &lt;=2500 are right\n1 - pbinom(q = 2500, size = 5000, prob = 0.51)\n\n[1] 0.9192858"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forest-recipe",
    "href": "slides/02-trees_and_forests.html#random-forest-recipe",
    "title": "Decision trees and random forests",
    "section": "Random forest recipe",
    "text": "Random forest recipe\nThe weak expert approach for decision trees:\n\nGrow each tree with a random subset of the training data.\n\n“In-bag” means in the random subset\n“Out-of-bag” means not in the subset\n\nEvaluate a random subset of predictors when splitting data.\n\nThese random elements help make the trees more independent while keeping their prediction accuracy better than random guesses."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#random-forest-predictions",
    "href": "slides/02-trees_and_forests.html#random-forest-predictions",
    "title": "Decision trees and random forests",
    "section": "Random forest predictions",
    "text": "Random forest predictions\nTo get a prediction from the random forest,\n\npredict the outcome with each tree\ntake the majority vote\n\nIn situations where trees predictions are continuous and you can’t take a majority vote, e.g., predicted 10-year risk for dementia, just take the mean of the tree’s predictions."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#a-single-tree-is-okay",
    "href": "slides/02-trees_and_forests.html#a-single-tree-is-okay",
    "title": "Decision trees and random forests",
    "section": "A single tree is okay",
    "text": "A single tree is okay\n\nAggregating randomized trees gives the classic random forest"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#trees-is-better",
    "href": "slides/02-trees_and_forests.html#trees-is-better",
    "title": "Decision trees and random forests",
    "section": "100 trees is better",
    "text": "100 trees is better\n\nAggregating randomized trees gives the classic random forest"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#more-trees-does-not-mean-overfitting",
    "href": "slides/02-trees_and_forests.html#more-trees-does-not-mean-overfitting",
    "title": "Decision trees and random forests",
    "section": "More trees does not mean overfitting",
    "text": "More trees does not mean overfitting\n\nAggregating randomized trees gives the classic random forest"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#how-to-get-out-of-bag-predictions",
    "href": "slides/02-trees_and_forests.html#how-to-get-out-of-bag-predictions",
    "title": "Decision trees and random forests",
    "section": "How to get out-of-bag predictions",
    "text": "How to get out-of-bag predictions"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#grow-tree-1",
    "href": "slides/02-trees_and_forests.html#grow-tree-1",
    "title": "Decision trees and random forests",
    "section": "Grow tree #1",
    "text": "Grow tree #1"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#store-its-predictions-and-denominators",
    "href": "slides/02-trees_and_forests.html#store-its-predictions-and-denominators",
    "title": "Decision trees and random forests",
    "section": "Store its predictions and denominators",
    "text": "Store its predictions and denominators"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#now-do-tree-2",
    "href": "slides/02-trees_and_forests.html#now-do-tree-2",
    "title": "Decision trees and random forests",
    "section": "Now do tree #2",
    "text": "Now do tree #2"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#accumulate-predictions-and-denominator",
    "href": "slides/02-trees_and_forests.html#accumulate-predictions-and-denominator",
    "title": "Decision trees and random forests",
    "section": "Accumulate predictions and denominator",
    "text": "Accumulate predictions and denominator"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#oblique-tree-first-split",
    "href": "slides/02-trees_and_forests.html#oblique-tree-first-split",
    "title": "Decision trees and random forests",
    "section": "Oblique tree: first split",
    "text": "Oblique tree: first split\n\nFirst, split mostly by bill length"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#oblique-tree-second-split",
    "href": "slides/02-trees_and_forests.html#oblique-tree-second-split",
    "title": "Decision trees and random forests",
    "section": "Oblique tree: second split",
    "text": "Oblique tree: second split\n\nFirst, split mostly by bill length\n\nSecond, make a triangle for the gentoo."
  },
  {
    "objectID": "slides/02-trees_and_forests.html#oblique-random-forests",
    "href": "slides/02-trees_and_forests.html#oblique-random-forests",
    "title": "Decision trees and random forests",
    "section": "Oblique random forests",
    "text": "Oblique random forests\n\nAggregating randomized trees gives the oblique random forest"
  },
  {
    "objectID": "slides/02-trees_and_forests.html#surprisingly-different",
    "href": "slides/02-trees_and_forests.html#surprisingly-different",
    "title": "Decision trees and random forests",
    "section": "Surprisingly different!",
    "text": "Surprisingly different!\n\nDespite very many similarities, axis-based and oblique random forests may give different results."
  },
  {
    "objectID": "slides/03-prediction_forests.html#overview",
    "href": "slides/03-prediction_forests.html#overview",
    "title": "Develop and evaluate prediction models",
    "section": "Overview",
    "text": "Overview\n\n\nSlides available at https://bcjaeger.github.io/melodem-apoe4-het/"
  }
]